---
title: "AI‑Augmented Engineering: Past the Hype, Toward Real Leverage"
authorHandle: marcoow
tags: [ai, process, mainmatter]
bio: "Marco Otte-Witte"
description: "…"
tagline: "<p>…</p>"
---

# Outline

* status quo
  * moved past peak hype, dust has settled
  * clear that what remains is neither
    * AGI and complete automation of everything
    * huge pile of shit and endless cleanup-after-ai projects
  * instead, substantial productivity increase
    * whatever percentage between 10% and 1000% you want to assume – tbd
    * doesn't matter: 10% is enough so every CTO needs to ask how to get it
  * our understanding is also not anymore CTOs are looking to lay off entire teams – instead of generating the same output with less input, the market will generate more output with the same input
    * software isn't done eating the world, it's just taking larger bites now
    * …and nobody can drop out of the accelerated rate unless they want to be left in the dust
    * the ability to move faster forces everyone to move faster (more output with same input, not same output with less input)
    * there are lots of (valid) concerns that many people still have though and it's important for leadership to take those serious
      (Clear communication from executives that AI tools are meant to augment, not replace developers helps build psychological safety.)
  * yet, not a trivial task, nobody really has experience, particularly not how to apply to larger organizations
* what gains are to be realized?
  * across the board:
    * accelerate code production obviously – super powerful auto-complete all the way to full agentic coding both code and tests
    * accelerate onboarding by making it easier to reason about a new codebase, e.g. creating diagrams of existing codebases, searching in codebases
    * assist in preparing work and defining architectures
    * DevOps & maintenance: debug issues
* what are risks and challenges?
  * hallucinations obviously & degraded quality
    * vibe coding fancy term but not what anyone actually does in prod for larger systems/teams
    * this ranges from just bad code to a mix of patterns and architectures
      * strong guardrails required both automated e.g. agents.md as well as human oversight
    * new skills need to be developed (how do I prompt etc.)
    * worst-case scenario is indeed what anit-AI people say: huge pile of shit and no way out
    * -> human in the loop required, also to remain in control of expertise
  * IP and Data security
    * accidental violations of open source licenses or using copyrighted material can happen – important to mitigate the risk
    * also teams' own source code will be leaked to AI – can be critical or not
    * worst case is leaking sensitive (user) data to AI
    * important to build infrastructure that prevents those
  * tooling complexity and fragmentation
    * fast pace of development and fragmentation of tools can lead to huge complexity when you use different tools all the time, constantly need to switch, different people use different tools etc.
  * accelerated code production ends up being problem if no stable delivery pipeline
    * deployments get larger, more complex
    * manual testing ends up being blocker for high velocity
  * -> all of the problems that companies with lack of engineering culture always had
    * strong engineering culture and infrastructure more important than ever
      * if you want to drive a formula 1 engine you need to have the right car, tires, and a race track – otherwise you just crash into a wall
        * (and your competition that has the right equipment drives circles around you)
    * & Mainmatter has worked with clients to improve for many years
* what's our role in this?
  * what does this mean for an engineering consultancy like mainmatter?
    * are our service no longer needed?
  * quite the opposite: we worked on improving teams for years:
    * better tech, better practices, better infrastructure
    * strong eng culture is more important than ever before
  * this is the next step: enabling teams to leverage AI effectively, sustainably, and reliably
    * companies that don't keep pace will fall behind and be left in the dust
  * what's the offering:
    1. assess the status quo: team size/composition/experience level, dev infrastructure, process practices, testing setup and practices, release and deployment strategy and process, production telemetry and analytics setup
    2. define a goal and roadmap together with the client team; in many cases first steps will be:
      1. ensure dev infrastructure is in place so it's not a blocker: full automated QA, continuous deployment process, telemetry
      2. set up AI tools and guardrails: agents.md, guidance for how to use CLI agents, infrastructure for agents to get feedback from CI etc.; potentially this includes e.g. writing additional MCP servers or CLI tools to expose more information to AI tools
      3. training for the team
* our new AI offering: …

# Draft

We’re no longer in the era of grandiose headlines proclaiming imminent AGI or universal code‑automation. That hype cycle has come and gone. The dust has settled and what remains is neither of the extremes many predicted. On one side: the notion that tomorrow all engineers will be redundant because machines will build everything. On the other: the fear that we’ve unleashed a tidal wave of half‑baked “AI projects” that leave nothing but cleanup work and chaos.
Instead, what we’re seeing is far more practical: a substantial productivity increase. Whether it’s ten percent, a few hundred percent, or even more doesn’t change the core point — even a modest boost is meaningful in a mature engineering organisation. A 10 % uplift in output or efficiency is enough for any CTO to ask: how can we get that here?
But—and this is important—it’s not a trivial transformation. There is no well‑worn playbook for applying AI at scale in existing large engineering teams. The tools are emerging. The patterns are still forming. The unknowns are real.

## What Gains Are To Be Realised?

When you set up the right environment, the benefits of integrating AI into engineering workflows go beyond novelty. They’re structural.

### Accelerating Code Production

Obviously, having better auto‑complete and scaffolding is a win. But when done well, the lift becomes much stronger: prompt‑based generation of modules, end‑to‑end agentic workflows that generate code and tests, even design prototypes—all while the engineer stays firmly in the driver’s seat. The engineer doesn’t disappear; they escalate.

### Onboarding New Folks

Bringing someone into a large codebase is expensive. What if their ramp‑up time could be dramatically shortened by AI tools that generate architectural diagrams of the existing code, answer natural‑language questions about modules or data flows, and let newcomers explore without fear? That ease of entry means your team becomes more adaptive and your talent pool deeper.

### Assisting Work Preparation & Architecture

Engineering waste is often caused by poor design, unclear interfaces, and slow feedback loops. AI can serve as a thinking partner: helping define architecture, assessing trade‑offs, spotting duplication, assistance in outlining service boundaries, and supporting the early phases of design. The engineer still decides—but with stronger inputs, earlier.

### DevOps & Maintenance

Once the code’s in production, the gains continue: AI can sift through logs, surface recurring patterns, help debug issues, prompt better root‑cause hypotheses, assist in analysis of performance regressions, and deliver suggestions for improvement. The velocity of change increases, not just in greenfield work but in maintenance and operations too.

## What Are The Risks and Challenges?

Now: none of the above happens by default. Many pitfalls lie in wait.

### Hallucinations and Quality Degradation

Yes—AI can generate plausible code. But plausibility isn’t correctness. In production systems, especially those with large teams and complex dependencies, hallucinations mean technical debt, subtle bugs, security holes, maintainability disasters. The “pile of shit” scenario anti‑AI commentators warn about is very real if humans are removed from the loop. You must keep human expertise in charge. Guardrails matter. Review processes matter.

### Accelerating Code Means Nothing If the Pipeline is Weak

If you enable your engineers to produce faster, but your delivery infrastructure can’t keep up, you’ll just push bad code real fast. Deployments become larger, more chaotic; manual testing becomes the bottleneck; rollbacks become frequent. The problems teams always had—lack of engineering culture, missing telemetry, brittle infra—get amplified by speed.

### The Same Old Engineering Culture Problems – Only Faster

In other words: when you adopt AI, you don’t leave your engineering fundamentals behind. You still need good practices, well‑automated pipelines, solid test coverage, observability, modular architecture. If you were weak in these before, you’ll now see faster failure. Teams that skipped gravity before are now skipping it at Mach speed.

## What’s Our Role in This?

For an engineering consultancy like Mainmatter, the rise of AI in software development naturally raises a question: are our services still needed if AI can write code now?

The reality is: they’re needed more than ever.

We’ve spent years helping engineering teams grow stronger — by improving their technology, refining their processes, and building better infrastructure. Those foundations don’t become less important in the age of AI. They become critical. Because the teams that gain real leverage from AI aren’t the ones with the fanciest tools — they’re the ones with strong engineering culture, modern delivery pipelines, and the ability to adapt fast.

That’s where we come in.

We see this as the next logical step in our work: enabling engineering teams to leverage AI effectively, sustainably, and reliably. Not through hype or hand‑waving, but through practical improvements that fit your context.

Companies that fail to adapt will fall behind. The pace of change isn’t slowing down — and teams without the fundamentals in place won’t be able to catch up.

Here’s how we help:

1. Assess the status quo

We take a close look at your engineering setup:
  •	Team size, composition, and experience level
  •	Dev infrastructure: CI/CD, test automation, deployment pipelines
  •	Engineering process and practices
  •	Testing strategy
  •	Release and deployment workflows
  •	Production telemetry, observability, and analytics

2. Define goals and a roadmap

Together with your team, we define what “AI leverage” should look like in your org. In many cases, the first steps include:

2.1. Unblocking the fundamentals

We make sure your development infrastructure supports high‑velocity work — with full test automation, continuous delivery, and the right telemetry in place.

2.2. Equipping the team with the right tools and guardrails

We help you set up and document usage patterns for AI tools (e.g. agents.md), provide guidance for using CLI‑based agents effectively, and build the infrastructure to close the feedback loop — like letting agents access CI results or runtime data. That might even mean writing custom MCP servers or CLI tools to expose more domain context to the AI.

2.3. Training your team

We enable your engineers to get the most out of these tools — without losing control, context, or quality. Training focuses on staying productive while keeping humans in the loop where it matters.

Read more about our offering at …
